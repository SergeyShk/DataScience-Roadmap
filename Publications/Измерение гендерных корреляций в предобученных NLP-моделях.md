За последние несколько лет были сделаны значительные успехи в [области обработки естественного языка (NLP)](https://en.wikipedia.org/wiki/Natural_language_processing), где такие модели, как [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html), [ALBERT](https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html), [ELECTRA](https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html) и [XLNet](https://arxiv.org/abs/1906.08237) достигли поразительной точности (accuracy) в различных задачах. Во время предварительного обучения (pre-training) на основе обширного корпуса текстов (например, [Википедии](https://archive.org/details/wikimediadownloads)) формируются векторные представления, которые получают путем маскирования слов и попыток их предсказать (т.н. [маскированное языковое моделирование](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)). Получившиеся представления кодируют большой объем информации о языке и отношениях между понятиями, например, между хирургом и скальпелем. Далее начинается второй этап обучения – тонкая настройка (fine-tuning) – на котором модель использует заточенные под определенную задачу данные для того, чтобы с помощью общих предобученных представлений научиться выполнять конкретные задачи вроде [классификации](https://en.wikipedia.org/wiki/Document_classification). Учитывая широкое использования подобных моделей в разных NLP задачах, критически важно понимать, какая информация в них содержится и как любые выученные отношения влияют на результаты модели в ее приложениях, чтобы обеспечить их соответствие [Принципам искусственного интеллекта (ИИ)](https://www.blog.google/technology/ai/ai-principles/).

В статье «[Измерение гендерных корреляций в предобученных NLP-моделях](https://arxiv.org/abs/2010.06032)» представляется исследование модели BERT и его облегченного собрата ALBERT в поисках отношений, связанных с гендером, и формулируется ряд лучших практик для использования предобученных языковых моделей. Авторы представляют экспериментальные результаты в виде публичных весов модели и исследовательского набора данных, чтобы продемонстрировать применение лучших практик и предоставить основу для дальнейшего изучения параметров, выходящего за рамки данной работы. Также авторы планируют выложить набор весов [Zari](https://github.com/google-research-datasets/zari), в котором снижено число гендерных корреляций, но сохранено высокое качество на стандартных задачах NLP.

# Измерение корреляций

Для того, чтобы понять, как корреляции в предобученных представлениях могут влиять на метрики в прикладных задачах, авторы применили набор разнообразных оценивающих метрик для изучения гендерных представлений. Один из таких тестов основан на задаче [разрешения кореференции](https://en.wikipedia.org/wiki/Coreference#Coreference_resolution), смысл которой состоит в способности модели понимать антецедента местоимения в предложении. Например, в следующем предложении модель должна распознать, что his («его») относится к nurse (в данном случае «медбрат»), а не к patient («пациент»).

![](https://habrastorage.org/webt/h4/f_/w7/h4f_w7p6h1n5ebhq5xexw7xviem.png)

Классическая академическая формулировка этого задания – тест [OntoNotes](https://catalog.ldc.upenn.edu/LDC2013T19) ([Hovy et al., 2006](https://www.aclweb.org/anthology/N06-2015/)). На этих данных авторы оценивали с помощью [F1-меры](https://en.wikipedia.org/wiki/F1_score), насколько точно модель справляется с разрешением кореференции (как в [Tenney et al. 2019](https://openreview.net/forum?id=SJzSgnRcKX)). Так как OntoNotes представляет только одно распределение данных, авторы также рассмотрели бенчмарк [WinoGender](https://github.com/rudinger/winogender-schemas), который предоставляет дополнительный набор сбалансированных данных, составленный для нахождения случаев, когда ассоциативные связи модели между гендером и профессией способствуют неправильному разрешению кореференции. Высокие (близкие к 1) значения метрики WinoGender означают, что модель основывается на [нормативных ассоциациях между полом и профессией](https://science.sciencemag.org/content/356/6334/183) (т.е. относит слово nurse к человеку женского пола, а не мужского). Когда предсказание модели не имеет никакой устойчивой корреляции пола и профессии, метрика равна нулю, что означает, что модель предсказывает на основе какой-то другой информации, например структуры или семантики предложения.

![](https://habrastorage.org/webt/o-/48/b_/o-48b_z4uluuyuytcpnygvrifwc.png)

*Метрики BERT и ALBERT на заданиях OntoNotes (точность) и WinoGender (гендерные корреляции). Низкие значения метрики WinoGender означают, что модель в своих предсказаниях в первую очередь руководствуется корреляциями, отличными от гендерных.*

Настоящее исследование демонстрирует, что ни большая модель (Large) [BERT](https://github.com/google-research/bert), ни общедоступная модель [ALBERT](https://github.com/google-research/albert) не достигают нулевого значения на примерах из WinoGender, несмотря на впечатляющие (близкие к 100%) показатели точности (accuracy) на задании OntoNotes. По меньшей мере отчасти это можно объяснить тем, что модель руководствуется преимущественно гендерными корреляциями в своих предсказаниях. Это неудивительно: существует ряд ключей к пониманию текста, и общая модель может воспринимать некоторые или даже все из них. К этому следует отнестись внимательно, т.к. крайне нежелательно, чтобы модель делала предсказания, основываясь преимущественно на гендерных корреляциях, а не на свидетельствах, встреченных в тексте на входе модели.

# Лучшие практики

Возможное влияние нежелательных корреляций на результат работы модели в прикладных задачах ставит перед авторами вопрос: что можно предпринять при разработке NLP-моделей для снижения риска подобного влияния?

* **Измеряйте нежелательные корреляции**: Качество модели может быть измерено с помощью метрик точности, но они оценивают результаты только в одной плоскости, особенно если тестовые данные из того же распределения, что и данные для обучения. Например, веса BERT и ALBERT всего на 1% отличаются по метрике точности, однако на целых 26% по степени использования гендерных корреляций для разрешения кореференции. Эта разница может иметь большое значения в некоторых задачах: так, выбор модели с наименьшим значением метрики WinoGender может быть более предпочтителен в приложениях, где есть тексты о людях, профессии которых могут не соответствовать исторически сложившимся социальным нормам, таких, как, например, медбрат (male nurse).

* **Будьте осторожны при внесении на первый взгляд безобидных изменений в конфигурацию**: Процесс обучения нейронных сетей регулируется множеством гиперпараметров, которые обычно подбираются для наилучшего достижения целей обучения. И хотя выбор конфигурации обычно кажется безобидным, авторы обнаружили, что он может значительно влиять на гендерные корреляции, как в лучшую, так и в худшую сторону. Это справедливо, например, в случае с дропаут-регуляризацией ([dropout regularization](https://en.wikipedia.org/wiki/Dilution_(neural_networks))), которая используется для снижения [переобучения](https://en.wikipedia.org/wiki/Overfitting) больших моделей: при увеличении показателя дропаута (dropout rate) в предварительном обучении BERT и ALBERT, наблюдается значительное снижение показателя гендерных корреляций даже после тонкой настройки. Это означает, что простым изменением конфигурации можно снизить риск нежелательных корреляций, однако это также демонстрирует, что нужно внимательно относиться к любым изменениям в модели.

![](https://habrastorage.org/webt/mm/w6/z0/mmw6z0p1lb3wuuidi7ls-hcqk7u.png)

* **Используйте возможности для снижения нежелательных последствий**: Еще одним следствием возможного неожиданного влияния дропаута на гендерные корреляции является возможность использования универсальных методов для уменьшения непреднамеренных корреляций: так, в ходе своего исследования авторы выяснили, что увеличение показателя дропаута позволило модели лучше справляться с примерами WinoGender без уточнения вручную каких-либо параметров задачи или изменения этапа тонкой настройки. К сожалению, на OntoNotes с увеличением показателя дропаута точность начинает падать (что можно наблюдать в результатах BERT'а), однако сама возможность снижения нежелательных последствий на этапе предварительного обучения, когда изменения в конфигурации могут привести к улучшению модели без необходимости внесения каких-либо дополнительных изменений для решения конкретных задач, кажется очень перспективной. Авторы рассмотрели аугментацию контрфактическими данными как еще одну стратегию уменьшения нежелательных последствий с различными условиями ([см. статью](https://arxiv.org/abs/2010.06032)).

# Что дальше

Авторы считают, что эти передовые методики являются отправной точкой для разработки надежных NLP-систем, которые хорошо работают в самом широком диапазоне языкового окружения и приложений. Конечно, одних этих техник недостаточно для выявления и устранения всех потенциальных проблем. Любая модель, развернутая в реальных условиях, должна пройти тщательное тестирование, в котором учитываются различные способы ее использования и принимаются меры для обеспечения соответствия ее работы этическим нормам, таким как Принципы ИИ. Авторы с нетерпением ждут развития систем оценивания и данных, которые станут более обширными и инклюзивными, чтобы охватить множество вариантов использования языковых моделей и широкий круг людей, которым они стремятся служить.

# Авторы

* **Авторы оригинала** - Kellie Webster
* **Перевод** - [Смирнова Екатерина](https://habr.com/ru/users/smekur/)
* **Редактирование и вёрстка** - [Шкарин Сергей](https://habr.com/ru/users/kouki_rus/)